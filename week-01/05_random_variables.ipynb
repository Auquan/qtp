{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is intellectual property of Auquan and is distributed under the [Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International Public License](https://creativecommons.org/licenses/by-nc-nd/4.0/legalcode). Any modification or distribution of this notebook without express permission of Auquan is prohibited and will result in legal prosecution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More About Normal Distribution\n",
    "Normal distribution is probably the most important one you'll encounter. Let's take a deep dive as to why:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "Most of the application of Normal Distributions derive from the central limit theorem (CLT). It states that the sum of many independent random variables tends toward a normal distribution, even if the original variables themselves are not normally distributed. This implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.\n",
    "\n",
    "For example, if we perform an experiment to generate a sample with a large number of observations, each observation being randomly generated in a way that does not depend on the values of the other observations and calculate the sum or average of these values. If this process is repeated many times, the central limit theorem says that the values of the average (or sum) will be distributed according to a normal distribution. \n",
    "\n",
    "Take a simple example: Let's say we flip a coin many times and sum the number of heads obtained in these flips. The probability of getting a given number of heads in a series of flips will approach a normal curve, with mean equal to half the total number of flips in each series. (In the limit of an infinite number of flips, it will equal a normal curve.)\n",
    "Below we plot the distribution for number of heads in 100 coin flips when the experiment is performed 50000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "number_heads = []\n",
    "for i in range(50000):\n",
    "    number_heads.append( sum( np.random.randint(2, size=100) ) )\n",
    "plt.hist(number_heads, bins = np.linspace(0,100,20), align = 'mid')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Occurences')\n",
    "plt.legend(['Die Rolls'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In modern portfolio theory, stock returns are generally assumed to follow a normal distribution. We use the distribution to model returns instead of stock prices because prices cannot go below $0$ while the normal distribution can take on all values on the real line, making it better suited to returns.  \n",
    "\n",
    "One major characteristic of a normal random variable is that a linear combination of two or more normal random variables is another normal random variable. This is useful for considering mean returns and variance of a portfolio of multiple stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 68-95-99.7 rule or 3 sigma rule\n",
    "\n",
    "This rule of thumb comes super handy in many situtations. It states that given the mean and variance of a normal distribution, we can make the following statements:\n",
    "\n",
    "* Around $68\\%$ of all observations fall within one standard deviations around the mean ($\\mu \\pm \\sigma$)\n",
    "* Around $95\\%$ of all observations fall within two standard deviations around the mean ($\\mu \\pm 2\\sigma$)\n",
    "* Around $99\\%$ of all observations fall within three standard deviations aroud the mean ($\\mu \\pm 3\\sigma$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardzing Random Variables to Normal Distribution\n",
    "\n",
    "**The power of normal dsitributions lies in the fact that using the central limit theorem, we can standardize different random variables so that they become normal random variables** \n",
    "\n",
    "We standardize a random variable $X$ by subtracting the mean and dividing by the variance, resulting in the standard normal random variable $Z$.\n",
    "\n",
    "$$\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Let's look at the case where $X$ **~** $B(n, p)$ is a binomial random variable. In the case of a binomial random variable, the mean is $\\mu = np$ and the variance is $\\sigma^2 = np(1 - p)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "p = 0.25\n",
    "\n",
    "# Draw 100000 samples from a binomial distribution\n",
    "X_samples = np.random.binomial(n, p, 100000)\n",
    "# Standardize the variable\n",
    "Z_samples = (X_samples - n * p) / np.sqrt(n * p * (1 - p))\n",
    "\n",
    "# Look at the distribution of X\n",
    "plt.hist(X_samples, bins = range(0, n + 2), align = 'left')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the distribution of Z\n",
    "plt.hist(Z_samples, bins=20)\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Probability');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea that we can standardize random variables is very important. By changing a random variable to a distribution that we are more familiar with, the standard normal distribution, we can easily answer any probability questions that we have about the original variable. This is dependent, however, on having a large enough sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Returns as Normal Distribution\n",
    "\n",
    "Let's assume that stock returns are normally distributed. Say that $Y$ is the price of a stock. We will simulate its returns and plot it.\n",
    "(This part won't work till you complete the `NormalRandomVariable` class above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "Y_initial = 100\n",
    "Y_returns = np.random.normal(0, 1, 1000) # generate 1000 daily returns\n",
    "Y = pd.Series(np.cumsum(Y_returns), name = 'Y') + Y_initial\n",
    "Y.plot()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that we have some other stock, $Z$, and that we have a portfolio of $Y$ and $Z$, called $W$.\n",
    "\n",
    "**Ex1: Write code below to simulate $Z$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to simulate and plot Z\n",
    "Z_initial = 100\n",
    "Z_returns = None # change this\n",
    "Z = None # change this\n",
    "\n",
    "if Z:\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Z not simulated properly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we simulate $W$, a portfolio of $Y$ and $Z$. Let's say we hold 20 stocks of $Y$ and 50 stocks of $Z$ in W. Then $W$ can be directly generated from a weighted sum of $Y$ and $Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Z_returns:\n",
    "    Y_quantity = 20\n",
    "    Z_quantity = 50\n",
    "    Y_weight = Y_quantity/(Y_quantity + Z_quantity)\n",
    "    Z_weight = 1 - Y_weight\n",
    "\n",
    "    W_initial = Y_weight * Y_initial + Z_weight * Z_initial\n",
    "    W_returns = Y_weight * Y_returns + Z_weight * Z_returns\n",
    "    W = pd.Series(np.cumsum(W_returns), name = 'Portfolio') + W_initial\n",
    "    W.plot()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Define Z first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct $W$ by taking a weighted average of $Y$ and $Z$ based on their quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if Z and W:\n",
    "    pd.concat([Y, Z, W], axis = 1).plot()\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Value');\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Define Z and W correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex2: Now plot the returns of our portfolio, $W$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# plot returns of W on a histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you find? The returns of $W$ are also normally distributed.\n",
    "#### Result: Any linear combination of normally distributed random variables is also a normal distribution "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
